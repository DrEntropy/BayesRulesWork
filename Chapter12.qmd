## Chapter 12 exercises.

* testing out doing this as QMD instead of IPYNB. Not sure how well it will work though!


```{python}
import arviz as az
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import pymc as pm
import bambi as bmb
import seaborn as sns
```



```{python}
eagles = pd.read_csv('bald_eagles.csv')
eagles.head()
```


```{python}
eagles.describe()
```


### Exercise 12.5

a) Look at count independant of the rest

```{python}
sns.histplot(eagles['count'])
```

b) Count vs year

 

```{python}
sns.scatterplot(data = eagles, x =  'year', y= 'count')
```

It does appear that the variance gets bigger as years go on, so a poissoin distribution could be tried.

c) Observation periods vary from year to year, from 134 to 248 hours. 
```{python}
sns.scatterplot(data = eagles, x =  'year', y= 'hours')
```


It looks like the spread in hours is rather uniform, but also that there is a jump around 2004, so that it is not independant of the year.

```{python}
sns.scatterplot(data = eagles, x =  'hours', y= 'count')
```

This tells us that hours have an (expected!) effect on the counts, so we will need to include (control for) that in our models.

### Exercise 12.7
 

```{python}
model1 = bmb.Model('count ~ year + hours', eagles, family='poisson')
model1.build()
model1.plot_priors()
```

:::{.callout-tip}
## Quarto issue

Needs cores=1 to avoid broken pipe error. 
:::

```{python}
results1 = model1.fit(draws=10000, chains=4,cores=1)
az.plot_trace(results1)
az.summary(results1)
```

Diagnostics look good, so moving on to look at the posterior check>

```{python}
model1.predict(results1, kind='pps', inplace= True)
az.plot_ppc(results1, num_pp_samples = 30)
```

This looks quite good to me.


### Exercise 12.8

```{python}
model2 = bmb.Model('count ~ year + hours', eagles, family='negativebinomial')
model2.build()
model2 
```

```{python}
model2.plot_priors()
```

I am not too sure what bambi is doing with `alpha` prior here, so once again i will use my own exponential prior


```{python}
alpha_prior = bmb.Prior('Exponential', lam= 1/50.)
model2 = bmb.Model('count ~ year + hours', eagles, family='negativebinomial',priors = {'alpha': alpha_prior})
model2.build()
model2 
```


```{python}
model2.plot_priors()
```

```{python}
results2 = model2.fit(draws=10000, chains=4,cores=1)
az.plot_trace(results2)
az.summary(results2)
```

Diagnostics look good, so moving on to look at the posterior check>

```{python}
model2.predict(results2, kind='pps', inplace= True)
az.plot_ppc(results2, num_pp_samples = 30)
```

Not sure it was worth all that extra trouble. Perhaps I am missing something,  because the count has a mean that is close to the standard deviation (across all years and hours). 

Based on this year and hours are both significant, but year is clearly the stronger predictor. 

Lets grab the raw samples so i can compute directly the quantile for the year coefficient.



```{python}
year_coeff_samples = results2.posterior.year.values.flatten()
np.quantile(year_coeff_samples,[.025,.975])
```



#### Ok i am going to redo this using `pymc` direct



### Exercise 12.9